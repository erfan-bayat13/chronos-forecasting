# Data paths and mixing probabilities
training_data_paths:
- "/home/ubuntu/tsmixup-data.arrow"
- "/home/ubuntu/kernelsynth-data.arrow"
probability:
- 0.9
- 0.1

# Model configuration 
model_id: "facebook/bart-base"
model_type: "bart"
architectures: ["ChronosBartForForecasting"]  # Specify the custom architecture

# Chronos BOLT specific configuration
chronos_config:
  context_length: 512
  prediction_length: 64
  input_patch_size: 16
  input_patch_stride: 8
  quantiles: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
  use_reg_token: false

# Training parameters
max_steps: 200_000
save_steps: 100_000
log_steps: 500
per_device_train_batch_size: 32
learning_rate: 0.001
optim: adamw_torch_fused
gradient_accumulation_steps: 1
min_past: 60

# Data processing
shuffle_buffer_length: 100_000
dataloader_num_workers: 1
max_missing_prop: 0.9

# Tokenizer configuration
tokenizer_class: "MeanScaleUniformBins"
tokenizer_kwargs:
  low_limit: -15.0
  high_limit: 15.0
n_tokens: 4096
n_special_tokens: 2
pad_token_id: 0
eos_token_id: 1
use_eos_token: true

# Infrastructure settings
tf32: true
torch_compile: true
output_dir: "./output_bart_bolt/"

# Model initialization
random_init: true
tie_embeddings: true